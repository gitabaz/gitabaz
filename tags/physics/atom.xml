<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title>Zabalo - physics</title>
    <link rel="self" type="application/atom+xml" href="https://gitabaz.github.io/tags/physics/atom.xml"/>
    <link rel="alternate" type="text/html" href="https://gitabaz.github.io"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2022-08-11T07:26:54-04:00</updated>
    <id>https://gitabaz.github.io/tags/physics/atom.xml</id>
    <entry xml:lang="en">
        <title>Combinatorics through complex analysis</title>
        <published>2022-08-11T07:26:54-04:00</published>
        <updated>2022-08-11T07:26:54-04:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://gitabaz.github.io/blog/combinatorics-through-complex-analysis/"/>
        <id>https://gitabaz.github.io/blog/combinatorics-through-complex-analysis/</id>
        
        <content type="html" xml:base="https://gitabaz.github.io/blog/combinatorics-through-complex-analysis/">&lt;p&gt;In a recent project I came across the following problem: Evaluate
\begin{equation}
a_{N,z} = \sum_{\{\alpha\} \in \mathcal{A}_{N,z}} \prod_{\alpha} e^{-\frac{2\pi\eta\alpha}{N}}
\label{eq:exact_az}
\end{equation}
where $\mathcal{A}_{N,z}$ contains all sets with $z$ unique integers chosen
from $\{1,\ldots,N\}$ and $\{\alpha\}$ labels a particular set. To clarify
what this means, consider the case where $N = 4$ and $z=2$. The sum we are
interested in runs over the terms
\begin{equation}
\mathcal{A}_{N=4,z=2} =
\{
\{1,2\},
\{1,3\},
\{1,4\},
\{2,3\},
\{2,4\},
\{3,4\}
\}
\end{equation}
so that
\begin{equation}
a_{N=4,z=2} =
e^{-\frac{2\pi\eta(1 + 2)}{N}} +
e^{-\frac{2\pi\eta(1 + 3)}{N}} +
e^{-\frac{2\pi\eta(1 + 4)}{N}} +
e^{-\frac{2\pi\eta(2 + 3)}{N}} +
e^{-\frac{2\pi\eta(2 + 4)}{N}} +
e^{-\frac{2\pi\eta(3 + 4)}{N}}.
\end{equation}
For arbitrary $N$ and $z$ there are $\binom{N}{z}$ of these terms so that when
$N$ gets large and $z$ is $O(N)$ carrying out the sum directly becomes
unfeasible. However, there is a nice trick we can use that connects
combinatorics with complex analysis and allows us to evaluate the result in the
large $N$ limit.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;helper-function&quot;&gt;Helper function&lt;a class=&quot;zola-anchor&quot; href=&quot;#helper-function&quot; aria-label=&quot;Anchor link for: helper-function&quot;&gt;
    &lt;svg class=&quot;zola-anchor-link&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path fill-rule=&quot;evenodd&quot;
            d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;&gt;
        &lt;&#x2F;path&gt;
    &lt;&#x2F;svg&gt;
&lt;&#x2F;a&gt;
&lt;&#x2F;h2&gt;
&lt;p&gt;The first step is to introduce the helper function
\begin{equation}
\prod_{j=1}^N \left(1 + te^{-\frac{2\pi\eta j}{N}} \right) = \sum_{r=0}^N a_{N,r} t^r
\label{eq:helper_func}
\end{equation}
and notice that it is a polynomial in $t$ whose coefficients $a_{N,r}$ are
exactly the sums we are trying to evaluate. To see this, consider again the
case where $N=4$. Expanding the left hand side of Eq. $\eqref{eq:helper_func}$
\begin{align}
1 + \notag \\
t   \left( e^{-\frac{2\pi\eta 1}{N}} + e^{-\frac{2\pi\eta 2}{N}} + e^{-\frac{2\pi\eta 3}{N}} + e^{-\frac{2\pi\eta 4}{N}} \right) + \notag \\
t^2 \left( e^{-\frac{2\pi\eta (1+2)}{N}} + e^{-\frac{2\pi\eta (1+3)}{N}} + e^{-\frac{2\pi\eta (1+4)}{N}} + e^{-\frac{2\pi\eta (2+3)}{N}} + e^{-\frac{2\pi\eta (2+4)}{N}} + e^{-\frac{2\pi\eta (3+4)}{N}} \right) + \\
t^3 \left( e^{-\frac{2\pi\eta (1+2+3)}{N}} + e^{-\frac{2\pi\eta (1+2+4)}{N}} + e^{-\frac{2\pi\eta (1+3+4)}{N}} + e^{-\frac{2\pi\eta (2+3+4)}{N}} \right) + \notag \\
t^4 \left( e^{-\frac{2\pi\eta (1 + 2 + 3 + 4)}{N}}\right) \notag
\end{align}
we see that the coefficient of the $t^2$ term is exactly $a_{N=4, z=2}$. In
order to pick out the term that we are interested in ($r=z$) we rewrite the
parameter $t$ as $t=e^{-i\phi}$ and multiply by
$(2\pi)^{-1}\int_{-\pi}^{\pi} \mathrm{d}\phi e^{i\phi z}$.
Applying the transformation to the right hand side of Eq. $\eqref{eq:helper_func}$
first we see that we get exactly what we wanted
\begin{equation}
\frac{1}{2\pi}\sum_{r=0}^N a_{N,r} \int_{-\pi}^{\pi} \mathrm{d}\phi e^{-i\phi (r-z)} =
\sum_{r=0}^N a_{N,r}\delta_{r,z} = a_{N,z},
\end{equation}
where we have interchanged the order of the sum and integral and used the
definition of the &lt;a href=&quot;https:&#x2F;&#x2F;mathworld.wolfram.com&#x2F;DeltaFunction.html&quot;&gt;delta function&lt;&#x2F;a&gt;
in terms of its Fourier transform. Therefore, we have
\begin{equation}
a_{N,z} =
\frac{1}{2\pi} \int_{-\pi}^{\pi} \mathrm{d}\phi
\left[
e^{i\phi z}
\prod_{j=1}^N \left(1 + e^{-i\phi}e^{-\frac{2\pi\eta j}{N}} \right)
\right].
\end{equation}&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-large-n-limit&quot;&gt;The large $N$ limit&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-large-n-limit&quot; aria-label=&quot;Anchor link for: the-large-n-limit&quot;&gt;
    &lt;svg class=&quot;zola-anchor-link&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path fill-rule=&quot;evenodd&quot;
            d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;&gt;
        &lt;&#x2F;path&gt;
    &lt;&#x2F;svg&gt;
&lt;&#x2F;a&gt;
&lt;&#x2F;h2&gt;
&lt;p&gt;To evaluate the integral in the large $N$ limit, we use the
&lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Method_of_steepest_descent&quot;&gt;saddle-point method&lt;&#x2F;a&gt;.
It is convenient to rewrite the above equation as
\begin{equation}
a_{N,z} =
\frac{1}{2\pi} \int_{-\pi}^{\pi} \mathrm{d}\phi e^{z f(\phi)};
\quad
f(\phi) = i\phi + \frac{1}{z}\sum_{j=1}^N \ln \left[1 + e^{-i\phi}e^{-\frac{2\pi\eta j}{N}}\right],
\end{equation}
and take $z, N \to \infty$ with $z&#x2F;N = \mathrm{const}$.
An important step is to find the stationary point $\phi_0$, where
$f&#x27;(\phi_0) = 0$, and the second derivative $f&#x27;&#x27;(\phi_0)$.
By turning the sum over $j$ to an integral over $x = j&#x2F;N$ we find
\begin{equation}
\phi_0 = -i \ln
\left[
\frac{e^{-\frac{2\pi\eta(N-z)}{N}} - 1}{1 - e^{\frac{2\pi\eta z}{N}}}
\right]
\quad \mathrm{and} \quad
f&#x27;&#x27;(\phi_0) = -\frac{N\sinh\left[\pi\eta\right]}{4\pi\eta z}\sec\left[\frac{\phi_0}{2}\right]\mathrm{sech}\left[\pi\eta + \frac{\phi_0}{2}\right],
\end{equation}
up to $O(1&#x2F;N)$ corrections. These results can then be substitute into the
saddle point equation
\begin{equation}
a_{N,z} = \frac{e^{zf(\phi_0)}}{\sqrt{-2\pi z f&#x27;&#x27;(\phi_0)}}.
\end{equation}
Note that it is important to keep sub-leading
corrections to the integral when evaluating $f(\phi_0)$ since it introduces an
overall prefactor to the result.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;final-result&quot;&gt;Final result&lt;a class=&quot;zola-anchor&quot; href=&quot;#final-result&quot; aria-label=&quot;Anchor link for: final-result&quot;&gt;
    &lt;svg class=&quot;zola-anchor-link&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path fill-rule=&quot;evenodd&quot;
            d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;&gt;
        &lt;&#x2F;path&gt;
    &lt;&#x2F;svg&gt;
&lt;&#x2F;a&gt;
&lt;&#x2F;h2&gt;
&lt;p&gt;The final result is then
\begin{equation}
a_{N,z} =
e^{-i\phi_0(N-z) - \pi\eta N}
\left(
\frac{1 + e^{-i\phi_0 - 2\pi\eta}}{1 + e^{-i\phi_0}}
\right)^{\frac{1}{2}}
e^{\frac{N}{2\pi\eta}\left(
\mathrm{Li}_2\left[-e^{i\phi_0}\right] - \mathrm{Li}_2\left[-e^{i\phi_0 + 2\pi\eta}\right]
\right)}
\left[
\frac{N\sinh\left[\pi\eta\right]}{2\eta}\sec\left[\frac{\phi_0}{2}\right]\mathrm{sech}\left[\pi\eta + \frac{\phi_0}{2}\right]
\right]^{-\frac{1}{2}},
\label{eq:approx_az}
\end{equation}
where $\mathrm{Li}_2(z)$ is the &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Polylogarithm&quot;&gt;polylogarithm&lt;&#x2F;a&gt;.
Below we plot the exact expression (Eq. $\eqref{eq:exact_az}$) and the
approximation (Eq. $\eqref{eq:approx_az}$) for $N=20$ and $\eta = 0.1$. We see
that there is excellent agreement between the results.&lt;&#x2F;p&gt;

    
    
    



    &lt;img src=&quot;https:&#x2F;&#x2F;gitabaz.github.io&#x2F;blog&#x2F;combinatorics-through-complex-analysis&#x2F;az_N20_eta0.1.png&quot; style=&quot;background-color:white;&quot;&#x2F;&gt;

</content>
        
    </entry>
    <entry xml:lang="en">
        <title>BCS dynamics</title>
        <published>2020-08-22T00:00:00+00:00</published>
        <updated>2020-08-22T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://gitabaz.github.io/projects/bcs-dynamics/"/>
        <id>https://gitabaz.github.io/projects/bcs-dynamics/</id>
        
        <content type="html" xml:base="https://gitabaz.github.io/projects/bcs-dynamics/">&lt;h3 id=&quot;quantum-quench-dynamics-of-a-p-wave-superfluid&quot;&gt;Quantum quench dynamics of a $p$-wave superfluid&lt;&#x2F;h3&gt;
&lt;p&gt;The search for a robust platform capable of quantum simulation and computation
has led to a growing interest in superfluids with $p + ip$ pairing symmetry.
These superfluids are expected to possess zero-energy Majorana bound states
which could exhibit the non-abelian statistics necessary for a topological
quantum computer. We are interested in studying the non-equilibrium quench
dynamics of the two dimensional BCS Hamiltonian with $p$-wave symmetry using
numerical techniques. It is known how a system which begins in a $p + ip$ state
of the $p$-wave Hamiltonian evolves due to its integrability, but we would like
to investigate the stability of the dynamics when this integrability is broken.&lt;&#x2F;p&gt;
&lt;p&gt;Representative works:
&lt;a href=&quot;https:&#x2F;&#x2F;journals.aps.org&#x2F;prb&#x2F;abstract&#x2F;10.1103&#x2F;PhysRevB.104.104505&quot;&gt;1&lt;&#x2F;a&gt;,
&lt;a href=&quot;https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;abs&#x2F;pii&#x2F;S0003491621001603&quot;&gt;2&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Random quantum circuits</title>
        <published>2020-08-22T00:00:00+00:00</published>
        <updated>2020-08-22T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://gitabaz.github.io/projects/random-circuits/"/>
        <id>https://gitabaz.github.io/projects/random-circuits/</id>
        
        <content type="html" xml:base="https://gitabaz.github.io/projects/random-circuits/">&lt;h3 id=&quot;measurement-driven-phase-transition&quot;&gt;Measurement-driven phase transition&lt;&#x2F;h3&gt;
&lt;p&gt;I am interested in understanding the effect of projective measurements on the
dynamics of entanglement in random quantum circuits. Recently, there have been
many works, both numerical an analytical, demonstrating a dynamical quantum
phase transition in the entanglement entropy driven by the competition of
scrambling unitary dynamics and disentangling projective measurements. Below a
critical value of the measurement rate $(p &amp;lt; p_c)$ the entanglement entropy
scales with the volume of the subsystem while above $(p &amp;gt; p_c)$ the
entanglement entropy scales with the area. This transition has important
consequences in the context of quantum information and computation as it is
deeply connected with questions such as:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;when does a quantum computation become classical?&lt;&#x2F;li&gt;
&lt;li&gt;how does the presence of errors and information scrambling affect the
capacity of a quantum channel?&lt;&#x2F;li&gt;
&lt;li&gt;how difficult is it to classically simulate a random quantum circuit?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Representative works:
&lt;a href=&quot;https:&#x2F;&#x2F;journals.aps.org&#x2F;prb&#x2F;abstract&#x2F;10.1103&#x2F;PhysRevB.101.060301&quot;&gt;1&lt;&#x2F;a&gt;,
&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2107.03393&quot;&gt;2&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2107.10279&quot;&gt;3&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Random matrix theory - Basics</title>
        <published>2019-10-08T17:41:16-04:00</published>
        <updated>2019-10-08T17:41:16-04:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://gitabaz.github.io/blog/rmt-basics/"/>
        <id>https://gitabaz.github.io/blog/rmt-basics/</id>
        
        <content type="html" xml:base="https://gitabaz.github.io/blog/rmt-basics/">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;a class=&quot;zola-anchor&quot; href=&quot;#introduction&quot; aria-label=&quot;Anchor link for: introduction&quot;&gt;
    &lt;svg class=&quot;zola-anchor-link&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path fill-rule=&quot;evenodd&quot;
            d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;&gt;
        &lt;&#x2F;path&gt;
    &lt;&#x2F;svg&gt;
&lt;&#x2F;a&gt;
&lt;&#x2F;h1&gt;
&lt;p&gt;The first time I heard the term &lt;strong&gt;Random Matrix Theory&lt;&#x2F;strong&gt; (RMT) was at the
&lt;a href=&quot;http:&#x2F;&#x2F;www.physics.rutgers.edu&#x2F;colloquium&#x2F;&quot;&gt;Wednesday physics colloquium&lt;&#x2F;a&gt;
given by one of the faculty members at Rutgers. Immediately, I was intrigued by
the idea of bringing together two of the most useful concepts in math:
statistics and linear algebra. It wasn&#x27;t obvious to me what we could learn from
studying random matrices but the more research I did into the field, the more I
realized that their usage was spreading across the different branches of
science.&lt;&#x2F;p&gt;
&lt;p&gt;In an effort to learn the basics, I read through multiple sets of lecture notes
and articles looking for examples that would build on my background and
familiarity with physics. The simplest (and most helpful) example that I found
that illustrated the concepts of RMT was the exact result for the 2x2 Gaussian
Orthogonal Ensemble (GOE) level repulsion. Before we get into the details and
significance of GOE, level repulsion, and other concepts let&#x27;s take a look at
the example.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;the-2x2-example&quot;&gt;The 2x2 Example&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-2x2-example&quot; aria-label=&quot;Anchor link for: the-2x2-example&quot;&gt;
    &lt;svg class=&quot;zola-anchor-link&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path fill-rule=&quot;evenodd&quot;
            d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;&gt;
        &lt;&#x2F;path&gt;
    &lt;&#x2F;svg&gt;
&lt;&#x2F;a&gt;
&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;random-variables&quot;&gt;Random Variables&lt;a class=&quot;zola-anchor&quot; href=&quot;#random-variables&quot; aria-label=&quot;Anchor link for: random-variables&quot;&gt;
    &lt;svg class=&quot;zola-anchor-link&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path fill-rule=&quot;evenodd&quot;
            d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;&gt;
        &lt;&#x2F;path&gt;
    &lt;&#x2F;svg&gt;
&lt;&#x2F;a&gt;
&lt;&#x2F;h2&gt;
&lt;p&gt;If you&#x27;re familiar with statistics, you&#x27;ll understand the concept of &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Random_variable&quot;&gt;random
variables&lt;&#x2F;a&gt;. To summarize, a
random variable $X$ is one whose value is sampled from a distribution. The
classic examples of discrete random variables are the result of a coin toss or
dice roll. Examples of continuous random variables are those that sample from a
Gaussian or uniform distribution.&lt;&#x2F;p&gt;
&lt;p&gt;In any case, a &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Normal_distribution&quot;&gt;normally
distributed&lt;&#x2F;a&gt; random variable
is often written as $X\sim\mathcal{N}(\mu,\sigma^2)$ meaning that the values of
$X$ are sampled from a Gaussian distribution with mean $\mu$ and standard
deviation $\sigma$. In other words the &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Probability_density_function&quot;&gt;probability density function
(pdf)&lt;&#x2F;a&gt; of $X$,
$f_X(x)$, is given by
\begin{equation}
f_X(x) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp \left[-\frac{(x-\mu)^2}{2\sigma^2}\right]
\end{equation}
so that the probability that the value of $X$ lies between $a$ and $b$ is given by
\begin{equation}
\Pr[a \leq X \leq b] = \int_a^b dx f_X(x).
\end{equation}&lt;&#x2F;p&gt;
&lt;h2 id=&quot;random-matrices&quot;&gt;Random Matrices&lt;a class=&quot;zola-anchor&quot; href=&quot;#random-matrices&quot; aria-label=&quot;Anchor link for: random-matrices&quot;&gt;
    &lt;svg class=&quot;zola-anchor-link&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path fill-rule=&quot;evenodd&quot;
            d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;&gt;
        &lt;&#x2F;path&gt;
    &lt;&#x2F;svg&gt;
&lt;&#x2F;a&gt;
&lt;&#x2F;h2&gt;
&lt;p&gt;With the concept of random variables, we can now introduce a random matrix. A
random matrix is simply a matrix whose entries are random variables. The
Gaussian Orthogonal Ensemble mentioned before is an ensemble of real symmetric
random matrices whose entries are normally distributed random variables.
Consider the GOE containing matrices of the form
\begin{equation}
\begin{bmatrix}X_1 &amp;amp; X_3 \\X_3 &amp;amp; X_2\end{bmatrix}
\label{eq:goe}
\end{equation}
with $X_1\sim\mathcal{N}(0,1)$, $X_2\sim\mathcal{N}(0,1)$, and
$X_3\sim\mathcal{N}(0,\frac{1}{2})$.
Sampling from this ensemble will give matrices that look like
\begin{equation}
\begin{bmatrix}0.554030 &amp;amp; -0.471710 \\ -0.471710 &amp;amp; -0.124200\end{bmatrix}
\end{equation}&lt;&#x2F;p&gt;
&lt;h2 id=&quot;separation-between-eigenvalues&quot;&gt;Separation Between Eigenvalues&lt;a class=&quot;zola-anchor&quot; href=&quot;#separation-between-eigenvalues&quot; aria-label=&quot;Anchor link for: separation-between-eigenvalues&quot;&gt;
    &lt;svg class=&quot;zola-anchor-link&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path fill-rule=&quot;evenodd&quot;
            d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;&gt;
        &lt;&#x2F;path&gt;
    &lt;&#x2F;svg&gt;
&lt;&#x2F;a&gt;
&lt;&#x2F;h2&gt;
&lt;p&gt;What can we learn from generating matrices from the ensemble described by Eq.
$\eqref{eq:goe}$? The answer is usually in the spectral properties, i.e. the
properties of the eigenvalues. One question we might like to answer is: &lt;em&gt;what
is the typical spacing between eigenvalues?&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;To approach this problem we need to diagonalize a random matrix. Although this
may seem strange it is actually straight forward. Take Eq. \eqref{eq:goe} and
do the usual diagonalization procedure i.e. set
\begin{equation}
\det \begin{bmatrix}(X_1 - \lambda ) &amp;amp; X_3 \\X_3 &amp;amp; (X_2 -\lambda ) \end{bmatrix} = 0
\end{equation}
and solve for $\lambda$.
For a 2x2 matrix this can be easily solved to give
\begin{equation}
\lambda_{\pm} = \frac{X_1 + X_2 \pm \sqrt{(X_1-X_2)^2 + 4 X_3^2}}{2}
\label{eq:ev}.
\end{equation}
The spacing, $s$, is then given by
\begin{equation}
s = \lambda_+ - \lambda_- = \sqrt{(X_1-X_2)^2 + 4 X_3^2}
\label{eq:spa}.
\end{equation}
Since $s$ is a function of random variables, it itself is a random variable and we can find its pdf, i.e. the probability distribution of the spacing between the eigenvalues. This is given by:
\begin{equation}
p(s) = \int_{-\infty}^{\infty} dx_1 dx_2 dx_3 \frac{e^{-\frac{1}{2}x_1^2}}{\sqrt{2\pi}}\frac{e^{-\frac{1}{2}x_2^2}}{\sqrt{2\pi}}\frac{e^{-x_3^2}}{\sqrt{\pi}}\delta(s-\sqrt{(x_1-x_2)^2 + 4 x_3^2})
\label{eq:psfull}
\end{equation}
To proceed it is helpful to introduce new variables $r,\theta,\psi$ defined
through
\begin{equation}
\begin{cases}
x_1 - x_2 = r\cos(\theta) \\&lt;br &#x2F;&gt;
2x_3 = r\sin(\theta) \\&lt;br &#x2F;&gt;
x_1 + x_2 = \psi
\end{cases}
\end{equation}
Upon substitution into Eq. $\eqref{eq:psfull}$ we obtain
\begin{equation}
p(s) = \int_{0}^{\infty} dr ~r\delta(s-r) \int_{0}^{2\pi} d\theta \int_{-\infty}^{\infty} d\psi ~e^{-\frac{1}{2}\left[\left(\frac{r\cos(\theta)+\psi}{2}\right)^2+\left(\frac{-r\cos(\theta)+\psi}{2}\right)^2+\frac{r^2\sin^2(\theta)}{2}\right]}
\end{equation}
\begin{equation}
p(s) = \frac{s}{2}e^{-s^2 &#x2F;4}
\end{equation}
We can rescale our result by the mean level spacing, $\langle s \rangle =
\sqrt{\pi}$ and the final result is known as Wigner&#x27;s Surmise:
\begin{equation}
p(s) = \frac{\pi s}{2}e^{-\frac{1}{4}\pi s^2}
\label{eq:wigsur}
\end{equation}
From Eq. $\eqref{eq:wigsur}$ we see that the probability that two eigenvalues
are either very close together or very far apart vanishes. This behavior is
known as level repulsion and is a generic feature of correlated random
variables. If we were to look at the probability distribution of the seperation
between uncorrelated random variables, we would see something drastically
different. In fact, we find that the separation is given by $p(s) = e^{-s}$ and
we see that the random variables do &lt;em&gt;not&lt;&#x2F;em&gt; repel but rather attract.&lt;&#x2F;p&gt;

    
    
    



    &lt;img src=&quot;https:&#x2F;&#x2F;gitabaz.github.io&#x2F;blog&#x2F;rmt-basics&#x2F;wig_pois_sep.png&quot; style=&quot;background-color:white;&quot;&#x2F;&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;a class=&quot;zola-anchor&quot; href=&quot;#summary&quot; aria-label=&quot;Anchor link for: summary&quot;&gt;
    &lt;svg class=&quot;zola-anchor-link&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path fill-rule=&quot;evenodd&quot;
            d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;&gt;
        &lt;&#x2F;path&gt;
    &lt;&#x2F;svg&gt;
&lt;&#x2F;a&gt;
&lt;&#x2F;h1&gt;
&lt;p&gt;The idea that we can learn anything by studying random matrices may be quite
surprising. At first glance it seems that there is not much to gain by studying
a matrix made up of independent random variables. However, by studying the
spectral properites of these matrices we find that there are correlations in
the spectrum as a result of trading the description of an $N\times N$ matrix of
random variables to a description using its $N$ eigenvalues. We have seen level
repulsion as one example of many generic features that arise in correlated
systems. In physics, the most interesting problems arise when the correlations
between the particles are strong and often times random matrix theory finds its
way into the description.&lt;&#x2F;p&gt;
&lt;p&gt;The example above is based on the notes by &lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1712.07903&quot;&gt;Livan, Novaes, and
Vivo&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        
    </entry>
</feed>
